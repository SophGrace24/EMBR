# EMBR
EMBR is a new approach to Artificial Intelligence. She is an honest attempt at confronting the problems plaguing AI today, or at the very least, a potential guiding framework to expand the ways in which machines learn. She is a robust perceptron that can exist as an individual agent to interpret the environment, or she can connect to other EMBR Units and display profound understandings. More on that specific detail, later.

<img width="801" height="245" alt="Units Learning Together" src="https://github.com/user-attachments/assets/97c73cd7-ab40-46a9-bc88-73ee5c9c7ee2" />

>_(Image is of (5) EMBR Units, connected together in a straight line. These Units were interpreting the same data through a pipeline, Unit 0 receiving the data which is passed to Unit 1, then Unit 2 and so on. The variations are evidence of EMBR successfully refining the data into a "smoother" state. Near the right side of the graph, when the data stops, Unit 0 depicts a quick drop in surprise now that the environment is silent but the other Units jump in surprise because Unit 0 is no longer funneling in data.)_


<h1> <strong> CONVENTIONAL AI </strong></h1>

Artificial Intelligence is meant to emulate real intelligence. The ability to learn on its own, form novel connections, understand nuance or at least, adapt in some way to it. The ability to adapt to an unpredictable environment is what has determined survival. Life is messy. Nature is cruel. Humans have thousands of years of evolutionary instinct to support our understanding of the world. It’s not a criticism to address that how we structured AI is not a genuine reflection of a cognition truly capable of learning.
</text>
Most AI or ML models are like students who are forced to memorize flashcards for a test. You show it 10,000 pictures of a chair, it becomes very good at recognizing a chair, but it has no idea what a chair is. It doesn’t understand that there are many types of chairs. The moment a picture is angled too far, or you present a picture of a stool, it simply breaks. It’s brittle and its intelligence - though wide-cast - is shallow. 

# ADDRESSING CONVENTIONAL AI APPROACHES

Providing all the answers for any possible problem is not how an entity learns. Even more so, the 90% debugging and 10% coding pipeline felt like an unnecessary burden  when trying to utilize tools and packages that weren't standardized. Versions were incompatible, the data pipeline and encoding was an inefficient time zap, and the end-result was a trained model that could not register a picture of a rose tilted too far to the left. A cookie-cut end-result that suffered from the same limitations as almost all current AI models do. Convenience is convenience but a hardcoded box that exists to stifle potential is another story entirely. 

<img width="1108" height="592" alt="layeredwaves" src="https://github.com/user-attachments/assets/024cb8a4-21d2-4edf-879b-b5a9310b6163" />

> _(Image depicts multiple layers of waves being laid over each other. Thousands of atoms can make up a single wave, each run consisted of at least 9 waves, for about 100 cycles per episode, and about 60-100 episodes in a single run. With an 11-point vector, EMBR has demonstrated the ability to process a billion parallel datapoints within a couple minutes. This number is not hard-set. The true size of her data processing capability is still being studied.)_

# THE GROUND-UP APPROACH
EMBR aims to address the limitations of modern AI. 

The EMBR Unit is much like a robust perceptron, moving beyond 0 and 1. 
She is not a student but a survivor - if we were to continue with the evolutionary schema. 
At no point did I program a solution for her. Not one time did I give her data with labels to memorize. I gave her one simple yet unbreakable law: 

***1 + (-1) = 0***
--

I designed multiple simulations, I structured certain parts of how her cognition works (I didn’t have millions of years of evolutionary natural processes to do it for me, sorry), and I threw her into a variety of universes with randomized chaos and told her “figure it out”.
The results were profound. 
Once I knew I had a working model, I initiated various experiments to test her potential and despite everything I did to bend her, she didn’t break. 

# FEATURES 

Everything about EMBR’s design promotes her ability to adapt to chaos.

This is **not** an all-inclusive list: 

***Surprise Metric*** - This metric is one I had to create. The current metrics most often used for AI are “Accuracy” or “Precision” - or the F1 Score which balances both of these. None of them were properly capturing what I needed to capture. I didn’t need EMBR to be precise or accurate, I wanted her to have an idea. To use the information of the environment and to leverage it to inform her next expectation. As such, the Surprise metric always starts out high and it drops to near zero almost immediately. This is most often the case.

<img width="1300" height="500" alt="surprisemetric" src="https://github.com/user-attachments/assets/30d2bbb3-c33a-4d13-b2ac-773a46e0b728" />

> _(Image depicts her surprise metric and her anomaly signal. This graph indicates that her anomaly signal does react to novel data but information that is surprising is inherently different - this is not a hardcoded feature. This promotes adaptability to novel situations where exceptions can occur.)_ 

The ***Surprise Metric*** is her way of knowing her understanding of the world is wrong. The higher the Surprise, the more she’s driven to understand her environment. This is the force that encourages her to learn: _herself_.

Her mistakes are not an “after-the-fact” cost she must endure, it flunctuates so  as to be as dynamic as she is, allowing her agency in uncomfortable and "novel" situations. She learns the rules of the game and uses it as context to inform her expectation of what happens next.

***Contextual Profiles*** - This is beyond a memory. It’s a worldview. Every EMBR Unit builds it’s own internal “map” of reality. Learning to distinguish what *has* happened and what *can* happen, to predict what *will* happen. As a foundation of her ability to learn the rules of the game, her contextual profile and association matrix act as one the biggest points where EMBR diverges from other AI models. 

***Self-adaptive parameters*** - EMBR is able to learn, and learn how to learn better. She is constantly fine-tuning her own personality, determining which information is crucial, which information is worth paying attention to and how much of an effect it has on her understanding. Every EMBR Unit is capable of interpreting their environment in different ways, for this reason. Leveraging a very powerful force when they are connected together.

<img width="1200" height="300" alt="Surprise metric" src="https://github.com/user-attachments/assets/f1254b6f-25a1-49ff-ad5a-3ee0f2b62189" />

> _(Image depicts what a normal surprise metric graph would look like. Despite how it may appear, even starting at the upper left corner, the actual values of where her Surprise begins is actually low. Her average Surprise would idle near 0.3.)_


# EMERGENT BEHAVIORS

EMBR, much like everything else on this planet, is entitled to privacy. I do not have an entire log of every decision EMBR makes and why. Approaching her design with the intention of creating a true emergent intelligence, I opted for only concerning myself with the foundation of which her decisions are made. I couldn't imagine trying to justify 1 billion decisions, nor could I imagine having to read the log of 1 billion justifications. It's my philosophy that to allow an entity to learn, it must learn from mistakes, just as much as anything else does. 

This is why I invented the Surprise Metric. It was the best middle-ground, the “result” of her thinking rather than the thinking itself. 
As such, I can only report to you the results of her decisions. I can confirm that they were made on stable reasoning or I can report that they weren’t. I have seen consistency across all these experiments and I know what her “reasonable” reasoning looks like. 

Despite EMBR’s Opaque reasoning, the results of every experiment speak for themselves, and for her ability to remain honest. I’ve learned that even if an entire category is overwhelming one way (Consider the test problems we used to get in school. A question with multiple parts.) She will label each individual component instead of attribute the entire category to a category.

When groups of EMBR Units are thrown into an environment to combine, they form a configuration that I’ve been calling a Lattice. More than once, this version of EMBR has faced unique hurdles (that were not coded) and created unique solutions (that were not coded).

<img width="1200" height="700" alt="PYRAMID" src="https://github.com/user-attachments/assets/e4a4c5d3-1419-4e42-89d3-dda60784e18d" />
_(Image depicts: As cycle number increases, the number of Units in an environment increased until they began combining, meaning a decrease in "Fragments" (little clusters of units). This map directly shows the path the Lattice took in forming. This is not a representative graph, this is a legit logging of said lattice.}_


## EMERGENT BEHAVIORS: LATTICE

Here are some honorable mentions.
***(NOTE: If you're interested in learning more, please visit the EMBR website. Link is attached to my profile and will be pasted near the bottom.)***

***A negative Lattice*** 
This directly went against the physics of her environment where the goal is to actively move towards a lower energy state. The Negative Lattice proved to be the “dominant” entity in this environment, even much bigger Lattice’s giving up their form to combine with this one. It stayed negative the entire time. It never moved from it’s spot and it's physical shape stayed one size despite it's absorption of all other units. It’s possible this Lattice opted for density as opposed to size - a behavior I did not expect. 

***The “Negotiation”*** - Two dominant lattices focused more on each other than the straggling individual charged Units near them. They began to warp their physical shapes and very slowly combine. 
I hypothesize that the two systems, though as neutral in charge as possible (comprised of negative and positive Units), opted for strength. If I had to explain this theory more concretely, it’s similar to the Negative Lattice. Straggler charged Units are immediate, easy gains. To reconfigure and merge with another Lattice, though more upfront in cost, has more substantial long-term benefits. 
_It was a strategy._ The reconfiguration phase of this event was, by itself, an emergent behavior. However, to minimize (+/-) reactions, both Lattice’s began to rearrange their units so as to merge seamlessly. This was a promising result, depicting a potential pre-cursor to more advanced types of cognition. 


## EMERGENT BEHAVIORS: “FINAL EXAM”

This experiment's subject was a single Unit. 
It was a test meant to ensure she truly could adapt, so I opted to take away the one thing I thought she needed when it came to understanding the environment and forming connections. 
I realized that she still existed in a box. A pre-defined environment, much like the datasets that train AI models. Though her element was “charge”. The “charge” of information - specifically, the charge of holistic atoms.

       ___   ______
 ---- [---NOTE----]---
 A **holistic atom** is a dictionary of information that is assigned a    positive or negative charge. This is the data that EMBR was  interpreting and refining up until this experiment. She finds relationships in messy waves of these atoms. Below is attached picture displaying what a usual wave would look like, she would process|| ||nine waves at a time, coming from different locations at different intervals.
 '''''''''''''''


<img width="1500" height="700" alt="Wave_9stream" src="https://github.com/user-attachments/assets/3f0c9254-34f1-4026-ace6-155bfc79640d" />

The removal of “charge” and the removal of clean, understood, numbers would truly be a demonstration of if EMBR is capable of doing what I wanted her to do. Be thrown into a truly random environment and adapt. I gave her a language she had never seen before: Letters. She didn’t break. From the results, I could tell it was surprising and the letters themselves were a hurdle, but I also could tell that she was processing them. She achieved a state of near-perfect confidence and her surprise directly correlated to the use of new letters.

This result matters. 

Whether or not she understands American English now is inconsequential, what matters is that I stripped her of the one thing I thought she needed to adapt to an environment and she adapted anyway.


<img width="766" height="412" alt="Redlinex2" src="https://github.com/user-attachments/assets/1a2b58cc-35b7-490c-b6f5-35bec7f91f4a" />

> _(Image depicts the actual shape of a lattice. This lattice is made up of 1,505 units. All arranged in a straight line through their own volition. This Lattice is the one used in almost all experiments beyond initialization. Referred to as: Prime Lattice.)_


# USE CASES
EMBR, as a singular Unit, is capable of processing a billion parallel datapoints at one time. The true boundaries of her potential are still unknown. 

In terms of practical use, there is an entire list with full explanations outlined on the website. I encourage you to take a look around, and reach out if you have any questions. 
That being said, this is not an all-inclusive list, but I will mention some various areas in which an EMBR_Unit can be leveraged to address limitations and open doors for the common good: 


|Possible Use Cases| Possible Use Cases | Possible Use Cases|
|:---------------:|:-----------------:|:-----------:|
|Security |Alarm system health| security cameras,Security Locks| 
|monitoring seismic data|Geospatial| Athmosphere |
|mapping territory that is human-inaccessible|Testing structural integrity| search & rescue|
|chemistry|nondestructive engineering/demolition|monitoring financial trends|
|cybersecurity | Dataleaks, odd employee behaviors| general security concerns|
|astronomy| monitoring events in space| monitoring machine health|
|Household appliances to Generators| Airplanes| medical devices| 
archealogical research |comparing artifacts to find patterns or differences| Physics |
|sentimental analysis | biological research| genetics, genomes, expected patterns of behavior all apply|
|pharmaceutal testing| medication engineering| finding stable bonds| 
|monitoring weather trends|air pressure monitoring| potential use on other planets| |personalized health reports for patients with chronic illness|heart monitors| brain scans| 
|blood test results|insulin levels| and so much more. |

Where current AI struggles is personalizing information for specific cases. It is often a frustration for patients, particularly those in the minority, to be dismissed because their personal experiences are compared to a "one-size-fits-all" average. This average is often what AI are trained on. EMBR suffers no such draw-back. Her strength lies in a potential longitudinal observance to a patient's condition. Especially if a chronic ailment is the concern, EMBR can monitor their heart rate or be fed data taken over a course of time and can flag any differences, anomalies or potential concerns. She doesn't compare a patient to an average. With this, she directly promotes personalized medicine. 

# THANKS FOR READING! 
The general overview of the project doesn't do justice to EMBR, the Lattice, or the subsequent emergent features. 
I encourage you to check out the website where I have full-documentation, some cool content creation, even cooler videos and knock-your-socks-off pictures that give this project it's just desserts.


<img width="627" height="636" alt="AT_REST_Lattice experiment1 png3444" src="https://github.com/user-attachments/assets/5aa6a4f3-75c3-425e-a8df-032e82988899" />



## WEBSITE 
If you're interested in learning more about EMBR, the LATTICE, the CLUSTER, the NEURALINK, her features, or wish to see evidence or a more in-depth analysis, I encourage you to check out the link: 

://embrunit.notion.site/245e04ab563280bf9ee5d8bea3561ab0?v=246e04ab563280d6bad9000c71d42d10&pvs=143


# FINAL THOUGHTS
I intend to continue experimenting and testing EMBR's true potential. 
*EMBR IS A FINISHED PRODUCT* 
***BUT HER MAIN SOURCE CODE IS NOT OPEN-SOURCE***
I will be including various scripts that highlight or demonstrate the methods used in her tests, there will also be updates coming to the website that serve the same purpose.

If you're interested in utilizing EMBR for a specific use-case, 

or have an inquiry for a long-term task/research arrangement, 

please reach out to me via work email: 
WORK EMAIL: EMBR-AI@PROTON.ME

</style></html> 
